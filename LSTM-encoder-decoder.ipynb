{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "use_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMVAE(nn.Module):\n",
    "    def __init__(self, lstm_layer = 1, seq_len = 10, input_dim = 5, hidden_dim = 10, batch_size = 1):\n",
    "        super(LSTMVAE, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm_enc = nn.LSTM(input_dim, hidden_dim, lstm_layer)\n",
    "        self.lstm_dec = nn.LSTM(int(hidden_dim / 2), input_dim, lstm_layer)\n",
    "        self.fc_mu = nn.Linear(hidden_dim, int(hidden_dim / 2))\n",
    "        self.fc_logvar = nn.Linear(hidden_dim, int(hidden_dim / 2))\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        self.seq_len = seq_len\n",
    "    \n",
    "    def encode(self, x):\n",
    "        h1, _ = self.lstm_enc(x)\n",
    "        h1 = self.tanh(h1)\n",
    "        return self.fc_mu(h1[-1]), self.fc_logvar(h1[-1])\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            if use_gpu:\n",
    "                eps = eps.cuda()\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "    \n",
    "    def decode(self, z):\n",
    "        z = z.expand(self.seq_len, -1, -1)\n",
    "        out, _ = self.lstm_dec(z)\n",
    "        out = self.tanh(out)\n",
    "        return out\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        out = self.decode(z)\n",
    "        return out, mu, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMVAE()\n",
    "if use_gpu:\n",
    "    model.cuda()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = nn.MSELoss()(recon_x, x.unsqueeze(1))\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs=8):\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        train_loss = 0\n",
    "        data = torch.randn([10, 5])\n",
    "        if use_gpu:\n",
    "            data = Variable(data.cuda())\n",
    "        else:\n",
    "            data = Variable(data)\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out, mu, z = model(data.unsqueeze(1))\n",
    "        loss = loss_function(out, data, mu, z)\n",
    "        loss.backward()\n",
    "        train_loss += loss.data[0]\n",
    "        optimizer.step()\n",
    "        print(train_loss)\n",
    "        print('input: {}'.format(data))\n",
    "        print('output: {}'.format(out.squeeze()))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "3.1889357566833496\n",
      "input: Variable containing:\n",
      "-1.1771 -0.3941 -0.0791  1.6708  1.1097\n",
      " 0.2297  0.2026  0.8844  0.3431  0.6123\n",
      " 0.9808  1.5825 -0.1166 -0.1829 -0.0835\n",
      "-0.9845  0.1240 -0.1499 -0.4636  0.7095\n",
      " 1.2399  0.0180 -0.6377 -0.0890 -1.3911\n",
      " 0.8953 -1.3431 -0.3679  0.7775 -1.0839\n",
      "-0.0379 -0.8397  1.7879 -1.8201 -2.8483\n",
      " 0.6125 -0.3064  0.0144  0.2854  0.7347\n",
      "-0.4322 -0.3648  2.6347 -0.4529  0.1817\n",
      "-1.9103  0.3955 -1.4532 -0.8341 -1.7567\n",
      "[torch.cuda.FloatTensor of size 10x5 (GPU 0)]\n",
      "\n",
      "output: Variable containing:\n",
      "-0.0339 -0.1853  0.2549 -0.1997 -0.1359\n",
      "-0.0475 -0.2754  0.3231 -0.2768 -0.2361\n",
      "-0.0534 -0.3142  0.3337 -0.3051 -0.3018\n",
      "-0.0561 -0.3315  0.3288 -0.3164 -0.3429\n",
      "-0.0575 -0.3398  0.3214 -0.3214 -0.3686\n",
      "-0.0581 -0.3439  0.3151 -0.3238 -0.3847\n",
      "-0.0585 -0.3461  0.3105 -0.3251 -0.3950\n",
      "-0.0587 -0.3472  0.3074 -0.3259 -0.4017\n",
      "-0.0588 -0.3478  0.3054 -0.3264 -0.4060\n",
      "-0.0588 -0.3481  0.3040 -0.3267 -0.4089\n",
      "[torch.cuda.FloatTensor of size 10x5 (GPU 0)]\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "1.4350793361663818\n",
      "input: Variable containing:\n",
      " 1.0792 -0.9404  1.0580  0.1944  0.3360\n",
      " 0.4188 -1.5127 -1.8492 -1.1935  0.0286\n",
      " 1.0495  1.5064 -0.0472 -1.3153  0.1959\n",
      "-0.1196 -1.7515  0.0399  1.3700 -1.4635\n",
      "-0.7448 -0.3670 -0.7548  0.3025 -0.0723\n",
      " 0.2873 -1.3338  1.7408  0.2400 -0.2183\n",
      " 1.8477  1.2513  0.4551 -0.6054 -0.9616\n",
      " 0.0865 -0.6576 -0.4150  2.3433  0.1366\n",
      " 1.4842  1.0839 -0.9385  0.3710  1.2576\n",
      "-0.1377  0.2023 -1.2738 -0.7358  0.2037\n",
      "[torch.cuda.FloatTensor of size 10x5 (GPU 0)]\n",
      "\n",
      "output: Variable containing:\n",
      "-0.0430 -0.0102  0.0834 -0.0019 -0.0351\n",
      "-0.0583 -0.0164  0.1244  0.0048 -0.0549\n",
      "-0.0639 -0.0196  0.1444  0.0102 -0.0651\n",
      "-0.0661 -0.0213  0.1544  0.0133 -0.0701\n",
      "-0.0669 -0.0221  0.1596  0.0150 -0.0725\n",
      "-0.0672 -0.0226  0.1623  0.0158 -0.0737\n",
      "-0.0672 -0.0228  0.1638  0.0162 -0.0743\n",
      "-0.0673 -0.0230  0.1646  0.0165 -0.0745\n",
      "-0.0673 -0.0231  0.1650  0.0166 -0.0747\n",
      "-0.0673 -0.0231  0.1652  0.0166 -0.0747\n",
      "[torch.cuda.FloatTensor of size 10x5 (GPU 0)]\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "1.7870925664901733\n",
      "input: Variable containing:\n",
      "-1.2632  0.3772  1.6490 -1.2009  0.5726\n",
      "-1.4283  1.0616  0.4690 -0.2670 -0.5228\n",
      " 0.1812 -0.1528  1.5937 -0.1067  0.6119\n",
      "-0.3000 -1.4679  1.9841 -0.1081  0.6739\n",
      " 0.8849  0.8935 -0.6609 -1.9542  0.1767\n",
      " 0.7121 -1.2266  1.0978  0.4314 -0.7588\n",
      " 0.5165 -0.4722  0.2043 -0.8013 -0.8936\n",
      " 0.9544 -1.4008  1.4481 -1.0139 -0.3159\n",
      " 0.4098  1.0272 -0.2306  1.1117  0.4538\n",
      "-1.0357  0.8767  0.6861 -0.2995 -2.4269\n",
      "[torch.cuda.FloatTensor of size 10x5 (GPU 0)]\n",
      "\n",
      "output: Variable containing:\n",
      " 0.1352  0.0802 -0.0491 -0.0504 -0.0812\n",
      " 0.1907  0.1115 -0.0820 -0.0744 -0.1186\n",
      " 0.2125  0.1245 -0.1046 -0.0864 -0.1341\n",
      " 0.2208  0.1304 -0.1206 -0.0927 -0.1402\n",
      " 0.2237  0.1333 -0.1320 -0.0960 -0.1425\n",
      " 0.2244  0.1349 -0.1403 -0.0978 -0.1432\n",
      " 0.2244  0.1358 -0.1463 -0.0988 -0.1434\n",
      " 0.2241  0.1363 -0.1508 -0.0994 -0.1434\n",
      " 0.2237  0.1367 -0.1540 -0.0998 -0.1433\n",
      " 0.2234  0.1370 -0.1565 -0.1000 -0.1432\n",
      "[torch.cuda.FloatTensor of size 10x5 (GPU 0)]\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "3.375352144241333\n",
      "input: Variable containing:\n",
      " 0.7090  0.0397 -0.5646 -0.0580 -0.0427\n",
      " 0.4805  0.7744 -0.1865 -0.5586  0.7135\n",
      "-0.1724 -0.7122 -0.4238  1.2380 -1.0741\n",
      "-0.9257  0.3987 -0.2174 -1.2998 -0.8217\n",
      "-1.7355  0.7079 -0.8708 -1.1745  0.8453\n",
      " 0.5289 -0.3770 -0.9170  0.3538  0.3094\n",
      " 0.1900  0.9680 -0.3775  0.3099  1.2465\n",
      " 0.3800 -1.0825 -0.5365 -0.7466 -1.9038\n",
      " 1.1476 -0.0618  1.4649  1.4584  0.2998\n",
      "-1.3169 -0.3168  0.7259 -0.5202 -0.0679\n",
      "[torch.cuda.FloatTensor of size 10x5 (GPU 0)]\n",
      "\n",
      "output: Variable containing:\n",
      "-0.0090 -0.1790  0.1537 -0.1574 -0.0386\n",
      "-0.0118 -0.2774  0.1870 -0.2395 -0.0789\n",
      "-0.0128 -0.3241  0.1841 -0.2810 -0.1133\n",
      "-0.0132 -0.3470  0.1739 -0.3042 -0.1397\n",
      "-0.0134 -0.3592  0.1644 -0.3183 -0.1589\n",
      "-0.0135 -0.3662  0.1572 -0.3274 -0.1727\n",
      "-0.0135 -0.3705  0.1522 -0.3334 -0.1824\n",
      "-0.0135 -0.3733  0.1486 -0.3375 -0.1893\n",
      "-0.0135 -0.3753  0.1462 -0.3402 -0.1942\n",
      "-0.0135 -0.3766  0.1445 -0.3422 -0.1976\n",
      "[torch.cuda.FloatTensor of size 10x5 (GPU 0)]\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "5.717892646789551\n",
      "input: Variable containing:\n",
      " 1.2462 -0.0710 -0.4864 -0.2205  0.7614\n",
      "-0.5451 -0.1146 -0.4615 -0.0806  1.6261\n",
      " 0.5985 -0.8577  0.4464  0.0850 -0.0570\n",
      " 0.2942 -0.4097  1.0935  0.2244 -0.8293\n",
      "-2.7480 -1.4339  0.4974  0.8968 -0.2135\n",
      "-1.1245 -0.7822  1.6396 -0.8597 -0.6198\n",
      " 1.1736 -2.1934 -1.5787 -0.1331  0.2752\n",
      "-0.6842 -0.7386  0.4146  0.7681  0.1703\n",
      "-1.0398 -1.2998  0.1677  0.6326 -0.7172\n",
      "-0.4985 -0.6108  1.0394  1.5598  1.3896\n",
      "[torch.cuda.FloatTensor of size 10x5 (GPU 0)]\n",
      "\n",
      "output: Variable containing:\n",
      "-0.1303 -0.2499  0.1285 -0.1341 -0.1198\n",
      "-0.1711 -0.3428  0.1879 -0.1498 -0.1401\n",
      "-0.1887 -0.3839  0.2186 -0.1483 -0.1440\n",
      "-0.1971 -0.4038  0.2364 -0.1459 -0.1445\n",
      "-0.2013 -0.4138  0.2476 -0.1445 -0.1442\n",
      "-0.2034 -0.4191  0.2549 -0.1436 -0.1440\n",
      "-0.2046 -0.4220  0.2598 -0.1431 -0.1438\n",
      "-0.2052 -0.4235  0.2632 -0.1428 -0.1436\n",
      "-0.2056 -0.4244  0.2656 -0.1427 -0.1435\n",
      "-0.2058 -0.4249  0.2672 -0.1425 -0.1435\n",
      "[torch.cuda.FloatTensor of size 10x5 (GPU 0)]\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "2.4303343296051025\n",
      "input: Variable containing:\n",
      "-0.8552 -0.6361 -0.2904  0.9059 -0.2206\n",
      " 1.4368 -0.1776 -0.0140  0.8468  1.4310\n",
      " 0.5369  0.1301  0.9551 -0.0312 -0.4301\n",
      " 0.5267 -0.3261 -0.7794  0.4454 -0.0816\n",
      " 1.8860  0.5836  0.6659 -1.2137  1.4374\n",
      "-1.6652  1.1205 -0.1820 -1.6852 -0.1149\n",
      " 0.0903 -1.6180  0.6200  1.1609 -0.2864\n",
      " 0.5866 -1.1255  0.2669 -1.8644  0.4037\n",
      " 1.0942  0.2899  0.5369  1.3228  0.4167\n",
      "-0.8990 -0.1253  0.2596  0.8521  1.3112\n",
      "[torch.cuda.FloatTensor of size 10x5 (GPU 0)]\n",
      "\n",
      "output: Variable containing:\n",
      " 0.1798  0.1897 -0.0335  0.0376  0.0231\n",
      " 0.2698  0.2358 -0.0323  0.0500  0.0485\n",
      " 0.3109  0.2452 -0.0211  0.0529  0.0668\n",
      " 0.3303  0.2459 -0.0092  0.0530  0.0779\n",
      " 0.3401  0.2449  0.0007  0.0527  0.0841\n",
      " 0.3452  0.2440  0.0082  0.0524  0.0874\n",
      " 0.3480  0.2433  0.0138  0.0522  0.0892\n",
      " 0.3497  0.2428  0.0178  0.0522  0.0901\n",
      " 0.3507  0.2425  0.0206  0.0522  0.0906\n",
      " 0.3514  0.2424  0.0226  0.0522  0.0909\n",
      "[torch.cuda.FloatTensor of size 10x5 (GPU 0)]\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "4.143205642700195\n",
      "input: Variable containing:\n",
      " 0.0904  0.1308  0.0075 -1.5950 -0.2930\n",
      "-0.2713 -0.8398 -0.7302  0.3857  1.6732\n",
      " 0.0106  1.1305  0.3556 -0.2835  1.4109\n",
      " 0.3588 -0.0719 -0.4508 -0.4510 -0.6987\n",
      "-0.2478  0.6806 -1.0295 -0.2739  0.3217\n",
      " 2.3996  0.4751  0.3227 -0.7049  0.7740\n",
      " 1.8537  2.0512  1.6483 -0.6587  1.4216\n",
      "-2.0512 -0.6188  1.6162 -1.2070 -0.7996\n",
      "-0.7464 -0.1271 -0.5847 -0.8301  0.2173\n",
      "-0.4777  0.1068 -0.7329 -1.7169  0.4435\n",
      "[torch.cuda.FloatTensor of size 10x5 (GPU 0)]\n",
      "\n",
      "output: Variable containing:\n",
      " 0.1725  0.0693 -0.1251 -0.0574 -0.1124\n",
      " 0.2125  0.0964 -0.2113 -0.0777 -0.1831\n",
      " 0.2206  0.1087 -0.2664 -0.0870 -0.2214\n",
      " 0.2211  0.1149 -0.3014 -0.0915 -0.2420\n",
      " 0.2201  0.1182 -0.3239 -0.0939 -0.2529\n",
      " 0.2191  0.1200 -0.3387 -0.0952 -0.2587\n",
      " 0.2182  0.1210 -0.3485 -0.0960 -0.2616\n",
      " 0.2175  0.1216 -0.3552 -0.0964 -0.2631\n",
      " 0.2170  0.1220 -0.3598 -0.0967 -0.2639\n",
      " 0.2166  0.1221 -0.3630 -0.0969 -0.2642\n",
      "[torch.cuda.FloatTensor of size 10x5 (GPU 0)]\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "1.9023381471633911\n",
      "input: Variable containing:\n",
      " 0.4286  0.0393  1.7006 -0.0121 -1.1340\n",
      " 0.2546  1.6987 -1.3127  0.3255 -0.4909\n",
      " 0.7633 -0.6625 -1.1460 -0.5338 -0.5103\n",
      " 0.1038 -0.1322 -1.0758 -1.8627 -1.0260\n",
      " 0.2188  0.2588 -1.2279  1.5781 -0.7330\n",
      "-0.4454  2.0944  0.6763 -0.2174 -2.2424\n",
      " 0.3698 -0.8570  0.1205  0.3154  1.9607\n",
      " 0.2204  1.8823 -1.4627 -0.7138  0.6602\n",
      "-0.8331  1.4122 -0.2785  0.2360 -0.1323\n",
      "-0.7709 -0.3674  0.1311 -0.1746  1.9591\n",
      "[torch.cuda.FloatTensor of size 10x5 (GPU 0)]\n",
      "\n",
      "output: Variable containing:\n",
      "-0.0585  0.0137  0.1887 -0.1019  0.0185\n",
      "-0.0781  0.0052  0.2627 -0.1421  0.0198\n",
      "-0.0844 -0.0048  0.2905 -0.1553  0.0166\n",
      "-0.0867 -0.0115  0.3006 -0.1590  0.0130\n",
      "-0.0878 -0.0150  0.3040 -0.1599  0.0100\n",
      "-0.0883 -0.0166  0.3050 -0.1599  0.0078\n",
      "-0.0886 -0.0172  0.3052 -0.1598  0.0062\n",
      "-0.0888 -0.0173  0.3051 -0.1597  0.0052\n",
      "-0.0889 -0.0172  0.3050 -0.1597  0.0045\n",
      "-0.0889 -0.0171  0.3049 -0.1597  0.0040\n",
      "[torch.cuda.FloatTensor of size 10x5 (GPU 0)]\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "2.241921901702881\n",
      "input: Variable containing:\n",
      "-0.5044 -0.4849 -0.8733  0.0557 -0.8158\n",
      " 0.0979 -0.7261 -1.0083 -0.2773 -0.0044\n",
      " 0.7851  1.2530  0.7322 -0.7406 -1.0641\n",
      " 0.8504  0.0618  0.8578  0.3024  0.8076\n",
      " 0.0138  1.6255 -1.1243 -0.4116  0.8066\n",
      " 0.2069  1.0129 -0.2719 -0.9957  0.6966\n",
      " 1.3915  0.0906  0.2584 -1.2031 -1.0804\n",
      "-1.6145 -0.3386  0.1547 -1.4179  0.0062\n",
      "-1.3114 -1.3239  0.6896  0.0939 -0.9902\n",
      " 0.7764  1.4116  0.5026 -0.1663  0.1178\n",
      "[torch.cuda.FloatTensor of size 10x5 (GPU 0)]\n",
      "\n",
      "output: Variable containing:\n",
      "-0.1958 -0.0942  0.2122 -0.1016 -0.1572\n",
      "-0.2602 -0.1224  0.2802 -0.0875 -0.2279\n",
      "-0.2855 -0.1299  0.3007 -0.0741 -0.2573\n",
      "-0.2956 -0.1311  0.3078 -0.0682 -0.2703\n",
      "-0.2997 -0.1308  0.3107 -0.0658 -0.2764\n",
      "-0.3013 -0.1302  0.3120 -0.0649 -0.2792\n",
      "-0.3020 -0.1299  0.3125 -0.0645 -0.2805\n",
      "-0.3022 -0.1296  0.3128 -0.0643 -0.2811\n",
      "-0.3023 -0.1295  0.3129 -0.0642 -0.2814\n",
      "-0.3023 -0.1295  0.3129 -0.0642 -0.2815\n",
      "[torch.cuda.FloatTensor of size 10x5 (GPU 0)]\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "1.4102787971496582\n",
      "input: Variable containing:\n",
      "-0.4535 -0.4169  1.3967 -0.2847  1.6099\n",
      " 0.1039 -1.5299 -0.1662  0.1718  1.5588\n",
      " 0.2930  0.5398  0.7275 -1.0349  1.4648\n",
      " 0.4965  0.5075  0.1303 -1.1609 -0.0633\n",
      "-0.0274  0.2821  1.1730 -0.1407 -1.1352\n",
      " 0.0694 -1.4962  1.3876 -0.2004  0.8108\n",
      " 0.8947  0.1093 -0.0887  0.4808  0.8576\n",
      "-0.4237 -0.0003 -1.5387 -2.3341 -0.3101\n",
      " 0.7723  1.0825 -0.3840  0.2961  0.3456\n",
      " 0.1596 -0.6223 -0.7125 -0.0981 -0.2202\n",
      "[torch.cuda.FloatTensor of size 10x5 (GPU 0)]\n",
      "\n",
      "output: Variable containing:\n",
      "-0.1594  0.0243  0.3597 -0.1330  0.0322\n",
      "-0.2372 -0.0018  0.4582 -0.1334  0.0230\n",
      "-0.2732 -0.0192  0.4850 -0.1138  0.0085\n",
      "-0.2900 -0.0256  0.4927 -0.1010 -0.0032\n",
      "-0.2981 -0.0268  0.4951 -0.0947 -0.0113\n",
      "-0.3020 -0.0264  0.4959 -0.0917 -0.0165\n",
      "-0.3039 -0.0256  0.4961 -0.0904 -0.0197\n",
      "-0.3049 -0.0250  0.4962 -0.0897 -0.0216\n",
      "-0.3053 -0.0245  0.4962 -0.0894 -0.0228\n",
      "-0.3055 -0.0242  0.4962 -0.0893 -0.0235\n",
      "[torch.cuda.FloatTensor of size 10x5 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = train(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
